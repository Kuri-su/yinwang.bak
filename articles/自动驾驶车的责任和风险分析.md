<div class="inner">
<h2>自动驾驶车的责任和风险分析</h2>
<p>说到“自动驾驶”，人们最熟悉的名字恐怕是 Tesla 的 Elon Musk 先生了。他总是对 Tesla 的 Autopilot 进行各种夸大宣传，让人误解 Autopilot 的能力。Autopilot 引起车祸死了人之后，Musk 先生总是在网上发话扭曲人们的逻辑，抓住“车主没有及时接管”等各种借口，逃避对事故的责任。</p>
<p>很多人对他的言论感到荒谬和愤怒，却又难以说清楚他到底哪里错了，甚至政府监管机构都对各自动驾驶公司的歪理无能为力。我发现对于自动驾驶车的责任和风险问题，人们仍然缺乏一个精确的，使人信服的说法，所以我一直在思索这些问题。</p>
<p>在本文里，我试图使用<strong>逻辑和概率</strong>的工具来分析自动驾驶车的责任和风险问题。虽然我用的数学可能不是那么的细节到位，但是你可以从中获得分析这类问题的思路。逻辑推理和概率分析不仅可以用于科学研究，而且可以用于法律和各种社会现象。</p>
<p>根据对 Elon Musk 的<a href="https://youtu.be/dEv99vxKjVI">采访</a>，你可以看出他的言论大体包含以下内容：</p>
<ul>
<li>全自动驾驶很快就要实现了，Autopilot 的视觉识别能力成指数增长，所以实现全自动驾驶就在眼前。</li>
<li>现在出产的 Tesla 车已经安装了具有“全自动驾驶能力”（FSD）的硬件。只要我们在不久的将来更新车里的软件，你就能拥有全自动驾驶的车，所以现在买 Tesla 的车是一种升值的财富，而不是贬值的物品。</li>
<li>统计数字显示，Autopilot 的事故率远远低于人类驾驶员。Autopilot 比人类驾驶员安全很多，这是不可争辩的事实。如果你否认这个事实，你就是危害公共安全。</li>
</ul>
<p><img src="https://www.yinwang.org/images/musk-safter-than-human.jpg" width="80%" /></p>
<p>虽然各种证据都说明 Autopilot 几乎没有自动驾驶能力，Elon Musk 却仍然在宣扬这些歪理。很多书呆子极客会听信他的“事故率”，为他所谓的“高科技”欢呼，甚至有人跟风说“Autopilot 比人类驾驶员安全 6 倍”。这些人都不明白，统计数字对于事故责任分析，对于 Autopilot 的风险评估都是没用的，而且他们的统计方法，解释统计数字的方式都是错误的。</p>
<p>在本文中我想说明以下几点：</p>
<ul>
<li>大范围的统计数字对于“责任”和“风险”的分析是没有任何关系的。</li>
<li>Autopilot 导致的任何一次车祸，Tesla 公司在法律上都是负有责任的。</li>
<li>要求驾驶员“随时接管”是推脱责任的手段，根本不符合法理。</li>
<li>自动驾驶行业对于车祸死亡率的数据解释是片面而错误的。由车祸引起的死亡，相对其它死亡因素并不是特别严重的问题。自动驾驶技术并不能降低车祸死亡率。</li>
</ul>
<h3 id="责任">责任</h3>
<p>Elon Musk 和其他很多自动驾驶公司都喜欢拿“事故率”说事，总是说自动驾驶比人类驾驶员安全，因为统计数字显示它们的事故率低，其实那相当于在说：“我活了这么久，为这么多客户服务，没杀过其中任何一个人，我杀人的概率非常低，低于全国的谋杀犯罪率，所以我现在杀了你没什么大不了的。”</p>
<p>先不说 Autopilot 的事故率是否真的那么低。即使它事故率是很低，难道弄死了人就可以不负责，甚至不受谴责吗？</p>
<p>到底 Tesla 有没有责任，我们可以使用逻辑学的因果关系“反事实分析”（counterfactual analysis）。假设驾驶员没有使用 Autopilot 而是自己开车，那么这次事故还会不会发生？如果不会发生，那么我们得到因果关系：Autopilot 导致了事故。不管其他人用 Autopilot 有没有出事故，事故占多大比例，面对这里的因果关系都是无关紧要的。因果关系等于责任。</p>
<p>如果是 Autopilot 导致了事故，即使总共只发生了一次事故，都该它的设计者 Tesla 公司负责。很多人都是混淆了“责任”和“事故率”，所以才会继续支持 Elon Musk 和 Tesla 的谬论。有些人以为“自动驾驶可能会降低全国的车祸率”，从而认为 Autopilot 引起少数几次车祸问题不大，而不明白“事故率”跟“责任”和“事故再次发生的风险”，完全是两码事。</p>
<p>另外，如果你看透了这些吹嘘得神乎其神的“<a href="http://www.yinwang.org/blog-cn/2019/09/14/machine-vs-human">机器的视觉能力</a>”有多假，就会知道“自动驾驶会降低车祸率”这个说法根本就不可能实现。</p>
<p>为什么我强调“责任”呢？因为人如果自己开车，不小心出了车祸伤到自己，他自己是可以接受的，因为是自己的责任。然而要是 Autopilot 判断错误引起车祸，撞伤了自己，对于车主来说这就是不可接受的，必然要追究 Tesla 公司的责任。</p>
<p>任何人都明白这个道理吧？这就跟自己开车不小心受了伤，和出租车司机不小心导致你受伤的差别一样。你会告那个出租车司机，你却不会上法庭告自己。简单吧？</p>
<p>每一次 Autopilot 相关的事故，Tesla 公司都会在事后散布新闻说是驾驶员开车不认真，手没有在方向盘上准备“随时接管”，所以不是 Autopilot 的责任。驾驶员是否认真在开车，人死了无所对证，但这些全都成为了 Tesla 公司推脱责任的借口。</p>
<p>如果发现 Autopilot 判断失误，你真来得及接管吗，你能在那么短的时间内做出正确的反应吗？就算你双手都在方向盘上，车到了离障碍物多近的地方不减速，你才会意识到它出错了，决定接管呢？恐怕到了自己接管的时候就已经晚了。所以要求车主随时接管，根本就不是一个合理的要求，不应该作为 Tesla 免责的理由。</p>
<h3 id="个人风险从航空业谈起">个人风险，从航空业谈起</h3>
<p>如果拿事故率说事，航空业的事故率远远低于汽车业了吧？可是为什么全世界好多年才发生一次空难，却每一次都带来那么多的舆论关注，进行那么严格的调查呢？就是因为我之前分析的，责任和事故率完全是两回事。</p>
<p>任何人或者交通工具本身的问题导致了事故，引起死伤，都是不会被放过的，不管他的总体事故率如何低，都一样要被惩罚。</p>
<p>另外责任的大小，舆论的大小，也与同一事故的死伤人数有关。如果是一个人开车不小心撞了，死了两个人，人们不会特别关注，因为“杀伤力”太小，只有 1:2。全国一年发生很多起这样的事故，就算总共死了几万人，都不会引起人们关注，因为平均每次事故还是只死了一两个人。人们知道那都是个别情况，小概率事件，只要自己小心开车，就不大可能会发生在自己身上。而且人们知道开车出点小碰撞是根本死不了人的，也就是说出车祸之后的存活率还挺高的。</p>
<p>可是如果一个飞行员操作失误，或者飞机故障导致 200 人丧生，就严重很多。好多年才死几百人，比起车祸每年死几万人，似乎小的可以忽略不计，可是为什么人们这么关心空难，而很少关心车祸死亡人数呢？首先，空难发生之后的存活率几乎为零，这跟普通车祸是没法比的，很可怕。另外，同一事故死亡人数很多，杀伤力为 1:200。</p>
<p>所以人们会开始怀疑那家航空公司的飞行员是不是培训不够严格，或者是不是有被迫加班，疲劳驾驶的情况。人们会怀疑那个型号的飞机是不是全都有设计或者质量问题。所以就那么一次空难，会导致“近期再次发生空难”的概率（所谓后验概率）大幅度上升。</p>
<p>这就是人们看到空难新闻如此关心的原因。人们关心的不是“总体事故率”，而是“自己遇上事故的概率”。我把这个概率叫做“个人风险”。</p>
<p>为什么波音 737 MAX 的空难引起这么大的风波呢？为什么以前的波音飞机空难都没有如此大的影响呢？甚至 9.11 事件发生的时候，两架波音飞机撞了大楼，引起几千人丧命，都没有对波音公司造成如此严重的打击。因为由于飞机的设计错误而导致的空难，和由于飞行员或者其它原因（比如劫机）而导致的空难，对“近期再次发生空难”的后验概率，对于“个人风险”的影响程度，是不一样的。</p>
<ul>
<li>如果是因为劫机引起空难，由于劫机的概率如此之小，特别是如果劫机发生在某个落后国家，人们知道那大概不会发生在自己身上，就不会很担心。个人风险很小。</li>
<li>如果由于某一个飞行员操作失误引起空难，人们的担心程度就大一些了。相关机构会严格调查飞机出事原因，调查那个航空公司，如果发现只是个别情况，那可以推断同样的空难不会再次发生。当然，很多人还是会因此回避那个航空公司，因为可能是他们迫使飞行员加班，疲劳驾驶导致的，所以同样的事情可能发生在该公司的其它飞行员身上。</li>
<li>可是要是飞机本身的设计原因，质量问题引起了空难，那么同样的故障可能在近期发生在所有同一型号的飞机上。那事就很大了，知情的人都会避免乘坐同一型号的飞机。这会对飞机制造公司的信誉造成长期而严重的打击。</li>
</ul>
<h3 id="autopilot-的个人风险分析">Autopilot 的个人风险分析</h3>
<p>这就是为什么每年几万起其它车祸没什么人关心，而 Autopilot 引起一两次车祸就这么多新闻舆论。因为要是车祸是由于 Autopilot 引起的，那么同样的车祸就可能发生在所有使用 Autopilot 的 Tesla 车主身上，“Autopilot 再次发生车祸”的后验概率就会大大提高。Autopilot 导致自己伤亡的风险就很高了。</p>
<p>这里的核心问题就在于，到底是人开车还是 Autopilot 开车。人和软件不仅在技术能力上有很大差别，对于概率风险分析，人和软件的效果也是很不一样的。简言之，人是“独立随机变量”，而 Autopilot 不是独立变量。</p>
<p>每个人都是不一样的，是独立的个体。有的人开车很稳，有的人开车一般，而少数人很鲁莽。这些人之间没有必然的联系，是“独立随机变量”。什么叫“独立”呢？意思是某个人自己开车不小心出车祸，其他人并不一定会出同样的车祸，因为每个人的开车方式都不一样。在概率论里面，这些人是否出现车祸完全是独立的事件。</p>
<p>而 Autopilot 是一个软件系统，所有安装 Autopilot 的车都有一模一样的行为方式，所以使用 Autopilot 的许多 Tesla 车不是独立变量，而是“相关变量”，它们通过 Autopilot 系统的设计关联在了一起。如果 Autopilot 因为判断错误导致一次车祸，那么所有使用 Autopilot 的车都很可能发生同样的车祸。</p>
<p>相应的随机变量是否“独立”，导致了人类驾驶员与 Autopilot 出现一次事故的风险分析完全不一样。</p>
<p>如果你学过概率论，那么 Autopilot 车主出事的“后验概率”（<a href="https://en.wikipedia.org/wiki/Posterior_probability">posterior probability</a>）会因为“Autopilot 引起一次车祸”的发生而大幅度提高，而如果是人开的汽车，那么它的后验概率基本不会因为另外一辆同型号车出事而提高。写成数学公式就是：</p>
<blockquote>
<p>P(其它 Autopilot 出车祸 | Autopilot 引起一次车祸)</p>
<p>远大于</p>
<p>P(其它非自动车出车祸 | 一辆非自动车出车祸)</p>
</blockquote>
<p>事故起因的随机性不同，后验概率也就随之不同。同理，对于之前的空难问题，你也可以使用类似的条件概率分析。再次发生空难的“后验概率”，根据某一次空难的起因，会有很大的差别。</p>
<blockquote>
<p>P(近期再次发生空难 | 飞机设计错误引起一次空难)</p>
<p>远大于</p>
<p>P(近期再次发生空难 | 飞行员操作失误引起一次空难)</p>
<p>大于</p>
<p>P(近期再次发生空难 | 劫机引起一次空难)</p>
</blockquote>
<p>面对“Autopilot 有一定概率会要了你的命”这一事实，不管 Autopilot 的总体事故率有多低，甚至像 Elon Musk 说的低于全国车祸率，对于 Tesla 车主来说都是毫无意义的。一是因为“责任”：车主可以允许自己要了自己的命，却不允许 Autopilot 或者其他人要了自己的命，更不允许是因为别人（Autopilot）的愚蠢而要了自己的命。二是因为“个人风险”：不管全国的事故率是多少，自己开车的风险一般只跟自己开车的小心程度有关，也就是说自己开车出事的概率基本是独立于全国事故率的。而使用 Autopilot，自己的风险就受到 Autopilot 能力的影响，跟 Autopilot 的平均事故率差不多了。</p>
<h3 id="仔细看看统计数字">仔细看看统计数字</h3>
<p>Autopilot 的事故率真的低吗？你可以自己研究一下。如果你算对了数学，恐怕它的事故率并不低。举一个例子，普通人只计算了事故的数目与 Autopilot 导航的总里程的比例，却忽视了那些由于驾驶员及时接管而避免了的事故的数目。</p>
<p>Autopilot 能不受打断的连续驾驶多少里程呢？按照现有的视觉技术，恐怕不会很远。聪明点的人都不会让 Autopilot 进入稍微复杂的局面，只用它进行“高速车道控制”，所以 Autopilot 事故率比较低的原因，很可能是因为大部分用户根本不在复杂的情况下使用它。所以虽然 Autopilot 统计数据看起来是“几十亿英里”，恐怕它从来没有在复杂的情况下做出过正确的反应。</p>
<p>另外 Tesla 属于比较贵的车，买车的人属于对自己比较负责的人，所以事故率不应该跟所有车比，而应该跟同样年代的奔驰，保时捷之类的车比。</p>
<p>我们来仔细看看汽车业的总体统计数字吧。美国 <a href="https://en.wikipedia.org/wiki/Motor_vehicle_fatality_rate_in_U.S._by_year">2017 年车祸死亡人数</a>是 3.7 万人。看上去很多，可是美国人口有 3.2 亿，2017 年车祸死亡人数只占总人口的 0.011%。另外按里程数的死亡率，每一亿英里平均只死了 1.16 人。从 1975 年到 2017 年，每一亿英里死亡人数从 3.35 人降低到了 1.16 人，所以即使没有 Autopilot，开车也是越来越安全了。</p>
<p><img src="https://www.yinwang.org/images/car-accident-death-rate.jpg" width="90%" /></p>
<p>对比一下<a href="https://www.cdc.gov/nchs/fastats/deaths.htm">其它死因</a>吧。美国 2017 年总共死亡 281 万人，其中因心脏病死亡 64.7 万人，癌症 59.9 万，呼吸道疾病 16 万，中风 14.6 万，意外伤害死亡 16.9 万（包括车祸），糖尿病 8.3 万，流感 5.5 万，自杀 4.7 万。</p>
<p>意外伤害死亡的 16.9 万里面包括了车祸的 3.7 万，所以另外 13.2 万人死于其它的意外。连自杀都有 4.7 万人。所以你可能意识到了，车祸死亡 3.7 万人并不是一个那么可怕的数字，而是相对来说最安全的领域之一了。</p>
<p><img src="https://www.yinwang.org/images/death-rate-2017.jpg" width="60%" /></p>
<p>你知道车祸死掉的都是什么人吗？他们是怎么开的车？只要自己小心开车，我不觉得自己的风险会有那么高，可能比得抑郁症想自杀的概率都要小。</p>
<p>Elon Musk 在<a href="https://youtu.be/dEv99vxKjVI">采访</a>中把汽车叫做“two-ton death machine”（两吨重的死亡机器），甚至说“难以置信我们居然允许人开车”，根本就是危言耸听。盲目的强调车祸死亡人数，号称可以降低事故率，就是自动驾驶领域常见的幌子。他们解决的并不是一个那么重要的问题，而且解决的方法根本就是<a href="http://www.yinwang.org/blog-cn/2019/09/14/machine-vs-human">不切实际的忽悠</a>。</p>
<p><img src="https://www.yinwang.org/images/musk-allowed-to-drive.jpg" width="70%" /></p>
<p>所以 Tesla 不但在技术上无法实现自动驾驶，而且人品和诚信都很成问题。我还没有见过一个汽车公司如此急于推脱责任的，一般都是积极配合调查，勇于承担责任，及时整改，这样才可能得到公众的信任。</p>
</div>
    