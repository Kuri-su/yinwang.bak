<div class="inner">
<h2>“AI 超人类视觉”是骗局</h2>
<p>我想再向大众解释一下，人工智能（AI）领域最关键的“突破”——“超人类视觉”是怎么来的。之前的<a href="http://www.yinwang.org/blog-cn/2019/09/14/machine-vs-human">文章</a>解释过，但可能信息被埋在比较长的内容里，很多人没看到，以至于仍然蒙在鼓里。对于这种关键问题，简洁易懂是非常重要的。由于这个概念关系到很多人的世界观，这篇文章希望广为转发。</p>
<p>简言之，AI 领域的所谓“机器视觉”，一个重要的问题就是让机器回答“图片上是什么东西？” 比如图片上是一辆汽车，如果你说是“汽车”，就算对了。所谓“Top-5 标准”，就是每张图片给你 5 次机会，让你说出是什么东西，只要有一次对了就算你对。用很多图片统计“识别率”，用于评比参与者。有人做了一个“人机对比”实验，机器的识别率看起来超过了人。</p>
<p>但这个比较的标准（Top-5）是不公平，不合理的，因为如果是人见过的东西，他只需要一次就对了，毫不含糊，另外 4 次机会完全没必要，而机器经常一次猜不对，需要另外 4 次机会才能“蒙混过关”。这就像设计一个考试，每道选择题本来只有一个正确答案，但却给了 5 次机会做对。这样就没法分清优等生和差等生了，甚至差等生有时候表现比优等生还好，因为不确切知道答案，瞎蒙都能做对。</p>
<p>我想一般人都理解这里的问题吧？然而这“Top-5”标准却是 AI 领域所谓“超人类视觉”（super-human level vision）的来源。其实就算用如此不公平的标准，机器的识别率也没超过人很多，几乎可以忽略，而且参加测试的只有一个人，然后他们就宣称“机器视觉超越了……人类”。</p>
<p>你可能以为这个“Top-5”标准虽然错误，也许没什么实际的害处，而其实它可以致命。人的生存环境里，往往是没有 5 次机会来判断一个东西是什么的，实际上经常只有一次机会。比如，如果在路上把“卡车”识别为“白板”，是可以致命的。这就是 Tesla 的 Autopilot 多次导致致命车祸的原因，详情可以参考这篇<a href="http://www.yinwang.org/blog-cn/2016/07/10/tesla-autopilot-fatal-crash">文章</a>。</p>
<p>这个测试其它的问题还有很多。比如，图片都是光照良好情况下的清晰图片，没有自然环境的各种复杂性，比如暗光，夜景，遮挡，阴影，反光，镜面，折射，模糊等。另外，只识别出物体“叫什么名字”，并不等于知道它的 3D 形状和边界，并不等于可以拿起，操作，或者避开物体，并不等于可以依靠它来做“自动驾驶”。</p>
<p>光就这一项简单的“识别任务”，使用如此不公平的标准，非常局限的数据，极少的测试参与者，几乎可忽略不计的差距，就说是“超人类视觉”，全世界地宣传，绝口不提是怎么得出结论的。我认为这是无耻的欺诈行为，是谋财害命的骗局。</p>
</div>
<!--
<div class="ad-banner" style="margin-top: 5px">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
                    style="display:inline-block;width:100%;height:90px"
                    data-ad-client="ca-pub-1331524016319584"
                    data-ad-slot="6657867155"></ins>
<script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
</div>
<script data-ad-client="ca-pub-1331524016319584" async
            src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js">
</script>
        -->
    